<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="s-Systems of Linear Equations">
<title>Systems of Linear Equations</title>
<index><main>Systems of Linear Equations</main></index>



<p>The method of solving systems of equations by matrices that we will look at is based on procedures involving equations that we are familiar with
from previous mathematics courses. The main idea is to reduce a given system of equations to another simpler system that has the same solutions.</p>

<definition xml:id="def-solution-set."><title>Solution Set</title>
<index><main>Solution Set</main></index>
<statement><p>Given a system of equations involving real variables \(x_1\), \(x_2 \ldots $\), \(x_n\), the solution set of the
system is the set of <m>n</m>-tuples in \(\mathbb{R}^n\), \(\left(a_1, a_2, \ldots ,a_n\right)\) such that the substitutions \(x_1= a_1\), \(x_2=
a_2, \ldots\), \(x_n= a_n\) make all the equations true.
</p></statement></definition>

 
<p>In terms of logic, a solution set is a truth set of a system of equations, which is a proposition over <m>n</m>-tuples of real numbers.</p>

<p>In general, if the variables are from a set <m>S</m>, then the solution set will be a subset of \(S^n\). For example, in number theory mathematicians
study Diophantine equations, where the variables can only take on integer values instead of real values.</p>

<definition xml:id="def-equivalent-systems"><title>Equivalent Systems of Equations.</title>
<statement><p> Two systems of linear equations are called equivalent if they have the same set of solutions.</p></statement></definition>



<example xml:id="ex-12.1.1."><title>12.1.1.</title><p></p></example> The previous definition tells us that if we know that the system

 $\quad $\(\begin{array}{l}
 4 x_1+2 x_2+x_3=1 \\
 2 x_1+x_2\text{    }+x_3=4 \\
 2 x_1+2 x_2+x_3=3 \\
\end{array}\)

is equivalent to the system

$\quad $\(\begin{array}{l}
 \text{   }x_1+0 x_2+0x_3=-1 \\
 0 x_1+x_2\text{   }+0x_3=-1 \\
 0 x_1+0 x_2\text{   }+x_3= 7 \\
\end{array}\)

then both systems have the solution set \(\{(-1, -1, 7)\}\). { }In other words, the values \(x_1=-1\), \(x_2= -1\), and \(x_3= 7\) are the only values
of the variables that make all three equations in either system true.

<theorem xml:id="theorem-12.1.1. Elementary Operations on Equations."><title>12.1.1. Elementary Operations on Equations.</title><index><main>12.1.1. Elementary Operations on Equations.</main></index><statement></statement><proof></proof></theorem> If any sequence of the following operations is performed on a system of equations, the
resulting system is equivalent to the original system:</p></li>
<li><p>Interchange any two equations in the system.</p></li>
<li><p>Multiply both sides of any equation by a nonzero constant.</p></li>
<li><p>Multiply both sides of any equation by a nonzero constant and add the result to a second equation in the system, with the sum replacing the latter
equation.



Let us now use the above theorem to work out the details of Example 12.1.1 and see how we can arrive at the simpler system..



Step 1. We will first change the coefficient of \(x_1\) in the first equation to one and then use it as a pivot to obtain 0's for the coefficients
of \(x_1\) in Equations 2 and 3.



\((1.1)\text{      }\text{   }\text{          }\text{Multiply} \text{Equation} 1 \text{by} \frac{1}{4} \text{to} \text{obtain}\text{   }\)



\((1.2)\text{$\quad $  }\text{       }\\\)



\((1.3)\quad \text{ $\quad $ }\\\)



\((1.4)\text{ $\quad $}\text{  $\quad $}\)

Note: We've explicitly written terms with zero coefficients such as \(0 x_1\) to make a point that all variables can be thought of as being involved
in all equations. { } After this example we will discontinue this practice in favor of the normal practice of making these terms <q>disappear.</q>



Step 2. We would now like to proceed in a fashion analogous to Step 1$---$namely, multiply the coefficient of \(x_2\) in the second equation by a
suitable number so that the result is 1. Then use it as a pivot to obtain 0's as coefficients for \(x_2\) in the first and third equations. This
is clearly impossible (Why?), { }so we will first interchange Equations 2 and 3 and proceed as outlined above.



\((2.1)\text{ $\quad $}\text{  $\quad $}\text{Interchange Equations 2 and 3 to obtain}\)



\((2.2)\text{ $\quad $}\text{  $\quad $}\text{Multiply Equation 2 by }-\frac{1}{2}\text{ and add
the result to Equation 1 to obtain}\)



 (2.3)$\quad $ { } { } { }\(\begin{array}{l}
 \text{    }x_1+ 0x_2+ 0x_3=-1 \\
 0x_1\text{     }+x_2\text{   }+\frac{x_3}{2}=\frac{5}{2} \\
 0x_1\text{  }+ 0x_2\text{  }+\frac{x_3}{2}=\frac{7}{2} \\
\end{array}\)



Step 3. Next, we will change the coefficient of \(x_3\) in the third equation to one and then use it as a pivot to obtain 0's for the coefficients
of \(x_3\) in Equations 1 and 2.



(3.1) $\quad $ { } { } { }\(\begin{array}{l}
 \text{    }x_1+ 0x_2+ 0x_3=-1 \\
 0x_1\text{     }+x_2\text{   }+\frac{x_3}{2}=\frac{5}{2} \\
 0x_1\text{  }+ 0x_2\text{  }+\frac{x_3}{2}=\frac{7}{2} \\
\end{array}\)$\quad $ { }\(\text{Multiply} \text{Equation} 3 \text{by} 2 \text{to} \text{obtain}\)



 (3.2) { } { } { } { } { } { } { } { }\(\begin{array}{l}
 \text{    }x_1+ 0x_2+ 0x_3=-1 \\
 0x_1\text{     }+x_2\text{   }+\frac{x_3}{2}=\frac{5}{2} \\
 0x_1\text{  }+ 0x_2\text{  }+x_3=7 \\
\end{array}\) { } { } \(\text{Multiply} \text{Equation} 3 \text{by} -\frac{1}{2} \text{and} \text{add} \text{the} \text{result}\\
\\
\text{to} \text{Equation} 2 \text{to} \text{obtain}\)



(3.3)$\quad $ { } \(\begin{array}{l}
 \text{    }x_1 + 0x_2\text{  }+ 0x_3=-1 \\
 0x_1\text{      }+x_2\text{   }+0x_3=-1 \\
 0x_1\text{  }+ 0x_2\text{      }+x_3=\text{  }7 \\
\end{array}\)



From the system of equations in Step 3.3, we see that the solution to the original system (Step 1.1) is \(x_1=-1\), \(x_2= -1\), and \(x_3= 7\) .



In the above sequence of steps, we note that the variables serve the sole purpose of keeping the coefficients in the appropriate location. This we
can effect by using matrices. The matrix of the system given in Step 1.1 is



$\quad \quad $ { }\(\left(
\begin{array}{cccc}
 4 &amp; 2 &amp; 1 &amp; 1 \\
 2 &amp; 1 &amp; 1 &amp; 4 \\
 2 &amp; 2 &amp; 1 &amp; 3 \\
\end{array}
\right)\)



where the matrix of the first three columns is called the coefficient matrix and the complete matrix is referred to as the augmented matrix. Since
we are now using matrices to solve the system, we will translate Theorem 12.1.1 into matrix language.

<definition xml:id="def-Elementary Row Operations."><title>Elementary Row Operations.</title><index><main>Elementary Row Operations.</main></index><notation><usage></usage><description></description></notation><statement><p></p></statement></definition>

 The following operations on a matrix are called elementary row operations:<ol label=“1”>
<li><p>{ }Interchange any two rows of the matrix.</p></li>
<li><p> { }Multiply any row of the matrix by a nonzero constant.</p></li>
<li><p> Multiply any row of the matrix by a nonzero constant and add the result to a second row, with the sum replacing the second row.

Definition: Row Equivalent. Two matrices, A and B, are said to be row-equivalent if one can be obtained from the other by any one elementary row
operation or by any sequence of elementary row operations.



If we use the notation \(R_i\) to stand for Row i of a matrix and \(\longrightarrow\) to stand for row equivalence, then



$\quad \quad $\(A \overset{c R_i+ R_j}{\longrightarrow }B\)



means that the matrix B is obtained from the matrix A by multiplying the Row <m>i</m> of <m>A</m> by <m>c</m> and adding the result to Row
<m>j</m>. { } The operation of multiplying row \textit{ i } by <m>c</m> is indicated by



$\quad \quad $\(A \overset{c R_i}{\longrightarrow }B\)



while interchanging rows <m>i</m> and <m>j</m> is denoted by



$\quad \quad $\(A \overset{R_i\leftrightarrow R_j}{\longrightarrow }B\).



The matrix notation for the system given in Step 1.1 with the subsequent steps are:



 { }$\quad $\(\left(
\begin{array}{cccc}
 4 &amp; 2 &amp; 1 &amp; 1 \\
 2 &amp; 1 &amp; 1 &amp; 4 \\
 2 &amp; 2 &amp; 1 &amp; 3 \\
\end{array}
\right)\text{    }\overset{\frac{1}{4} R_1}{\text{  }\longrightarrow }\text{   }\left(
\begin{array}{cccc}
 1 &amp; \frac{1}{2} &amp; \frac{1}{4} &amp; \frac{1}{4} \\
 2 &amp; 1 &amp; 1 &amp; 4 \\
 2 &amp; 2 &amp; 1 &amp; 3 \\
\end{array}
\right) \text{         }\overset{-2 R_1+ R_2}{\text{  }\longrightarrow }\text{    }\left(
\begin{array}{cccc}
 1 &amp; \frac{1}{2} &amp; \frac{1}{4} &amp; \frac{1}{4} \\
 0 &amp; 0 &amp; \frac{1}{2} &amp; \frac{7}{2} \\
 2 &amp; 2 &amp; 1 &amp; 3 \\
\end{array}
\right) \\
\\
 \text{                             }\overset{-2 R_1+ R_3}{\text{  }\longrightarrow }\text{    }\left(
\begin{array}{cccc}
 1 &amp; \frac{1}{2} &amp; \frac{1}{4} &amp; \frac{1}{4} \\
 0 &amp; 0 &amp; \frac{1}{2} &amp; \frac{7}{2} \\
 0 &amp; 1 &amp; \frac{1}{2} &amp; \frac{5}{2} \\
\end{array}
\right)\text{   }\overset{R_2\leftrightarrow R_3}{\text{  }\longrightarrow }\text{   }\left(
\begin{array}{cccc}
 1 &amp; \frac{1}{2} &amp; \frac{1}{4} &amp; \frac{1}{4} \\
 0 &amp; 1 &amp; \frac{1}{2} &amp; \frac{5}{2} \\
 0 &amp; 0 &amp; \frac{1}{2} &amp; \frac{7}{2} \\
\end{array}
\right) \\
\\
\text{                                  }\overset{-\frac{1}{2} R_2+ R_1}{\text{  }\longrightarrow }\text{     }\left(
\begin{array}{cccc}
 1 &amp; 0 &amp; 0 &amp; -1 \\
 0 &amp; 1 &amp; \frac{1}{2} &amp; \frac{5}{2} \\
 0 &amp; 0 &amp; \frac{1}{2} &amp; \frac{7}{2} \\
\end{array}
\right)\text{  }\overset{2 R_3}{\text{  }\longrightarrow }\text{    }\left(
\begin{array}{cccc}
 1 &amp; 0 &amp; 0 &amp; -1 \\
 0 &amp; 1 &amp; \frac{1}{2} &amp; \frac{5}{2} \\
 0 &amp; 0 &amp; 1 &amp; 7 \\
\end{array}
\right)  \text{  }\\
\\
\text{$\quad \quad $   }\overset{-\frac{1}{2} R_3+ R_2}{\text{  }\longrightarrow }\text{  }\left(
\begin{array}{cccc}
 1 &amp; 0 &amp; 0 &amp; -1 \\
 0 &amp; 1 &amp; 0 &amp; -1 \\
 0 &amp; 0 &amp; 1 &amp; 7 \\
\end{array}
\right)\)



This again gives us the solution. This procedure is called the \textit{ Gauss-Jordan elimination method}.



It is important to remember when solving any system of equations via this or any similar approach that at any step in the procedure we can rewrite
the matrix in <q>equation format</q> to help us to interpret the meaning of the augmented matrix.



In Example 12.1.1 we obtained a unique solution, only one triple, namely \((-1,-1,7)\), which satisfies all three equations. For a system involving
three unknowns, are there any other possible results? To answer this question, let's review some basic facts from analytic geometry.



The graph of a linear equation in three-dimensional space is a plane. So geometrically we can visualize the three linear equations as three planes
in three-space. Certainly the three planes can intersect in a unique point, as in Example 12.1.1, or two of the planes could be parallel. If two
planes are parallel, there are no common points of intersection; that is, there are no triple of real numbers that will satisfy all three equations.
Also, the three planes could intersect along a common axis or line. In this case, there would be an infinite number of real number triples in \(\mathbb{R}^3\)
that would satisfy all three equations. { }Finally if all three equations describe the same plane, the solution set would be that plane. { } We generalize;



In a system of n linear equations, n unknowns, there can be:

<ol label=“1”>
<li><p>{ }a unique solution,

</p></li>
<li><p> { }no solution, or

</p></li>
<li><p> { }an infinite number of solutions.



To illustrate these points, consider the following examples:

<example xml:id="ex-12.1.2."><title>12.1.2.</title><p></p></example> Find all solutions to the system

 { }$\quad $\(\begin{array}{l}
 \text{   }x_1 +3 x_2\text{    }+x_3=2 \\
 \text{    }x_1\text{   }+x_2 +5 x_3=4 \\
 2 x_1+2 x_2+10 x_3=6 \\
\end{array}\)

The reader can verify that the augmented matrix of this system, 

 $\quad \quad \quad $\(\left(
\begin{array}{cccc}
 1 &amp; 3 &amp; 1 &amp; 2 \\
 1 &amp; 1 &amp; 5 &amp; 4 \\
 2 &amp; 2 &amp; 10 &amp; 6 \\
\end{array}
\right)\),

reduces to 

$\quad \quad \quad $\(\left(
\begin{array}{cccc}
 1 &amp; 3 &amp; 1 &amp; 2 \\
 1 &amp; 1 &amp; 5 &amp; 4 \\
 0 &amp; 0 &amp; 0 &amp; -2 \\
\end{array}
\right)\) { } { } { } { } { }(See exercise 4 of this section.)

We can row-reduce this matrix further if we wish. However, any further row-reduction will not substantially change the last row, which, in equation
form, is \(0x_1+ 0x_2+0x_3 = -2\), or simply \(0=-2\). It is clear that we cannot find real numbers \(x_1\), \(x_2\), and \(x_3\) { }that will satisfy
this equation, hence we cannot find real numbers that will satisfy all three original equations simultaneously. When this occurs, we say that the
system has no solution, or the solution set is empty.

<example xml:id="ex-12.1.3."><title>12.1.3.</title><p></p></example> Next let's attempt to find all of the solutions to:

$\quad \quad $\(\begin{array}{l}
 \text{   }x_1+6 x_2+2 x_3=1 \\
 2 x_1\text{   }+x_2+3 x_3 =2 \\
 4 x_1+2 x_2+6 x_3=4 \\
\end{array}\)

The augmented matrix for the system,

 $\quad \quad $\(\left(
\begin{array}{cccc}
 1 &amp; 6 &amp; 2 &amp; 1 \\
 2 &amp; 1 &amp; 3 &amp; 2 \\
 4 &amp; 2 &amp; 6 &amp; 4 \\
\end{array}
\right)\)

reduces to 

 $\quad \quad $\(\left(
\begin{array}{cccc}
 1 &amp; 0 &amp; \frac{16}{11} &amp; 1 \\
 0 &amp; 1 &amp; \frac{1}{11} &amp; 0 \\
 0 &amp; 0 &amp; 0 &amp; 0 \\
\end{array}
\right)\)

If we apply additional elementary row operations to this matrix, it will only become more complicated. In particular, we cannot get a one in the
third row, third column. Since the matrix is in simplest form, we will express it in equation format to help us determine the solution set.

$\quad \quad $\(\begin{array}{l}
 x_1\text{             }+\frac{16 }{11}x_3=1 \\
 \text{             }x_2+\frac{1}{11}x_3 =0\quad 0\text{                 }=0 \\
\end{array}\)

Any real numbers will satisfy the last equation. However, the first equation can be rewritten as { }\(x_1 =1-\frac{16 }{11}x_3\), which describes
the coordinate \(x_1\) in terms of \(x_3\) . Similarly, the second equation gives \(x_1\)in terms of \(x_3\) . A convenient way of listing the solutions
of this system is to use set notation. If we call the solution set of the system <m>S</m>, then

$\quad $ \(S = \left\{\left(1-\frac{16}{11}x_3, -\frac{1}{11}x_3, x_3\right) |\text{  }x_3\in \mathbb{R}\right\}\).

What this means is that if we wanted to list all solutions, we would replace \(x_3\) by all possible numbers. Clearly, there is an infinite number
of solutions, two of which are \((1, 0, 0)\) and \((-15, -1, 11)\).

A Word Of Caution: Frequently we may obtain <q>different-looking</q> $\unicode{00ad}$answers to the same problem when a system has an infinite number
of answers. Assume a student{'}s solutions set to Example 12.1.3 is \(A = \left\{\left(1+16x_2, x_2, -11x_3\right) |\text{  }x_3\in \mathbb{R}\right\}\).
Certainly the result described by <m>S</m> looks different from that described by <m>A</m>. To see whether they indeed describe the same set,
we wish to determine whether every solution produced in <m>S</m> can be generated in <m>A</m>. For example, the solution generated by \textit{
S }when \(x_3=11\) is \((-15, -1, 11)\). { }The same triple can be produced by <m>A</m> by taking \(x_2= -1\). We must prove that \textit{ every}
solution described in <m>S</m> is described in <m>A</m> and, conversely, that every solution described in <m>A</m> is described in \textit{
S}. (See Exercise 6 of this section.)



To summarize the procedure in the Gauss-Jordan technique for solving systems of equations, we attempt to obtain 1{'}s along the main diagonal of
the coefficient matrix with 0{'}s above and below the diagonal, as in Example 12.1.1. We may find in attempting this that the closest we can come
is to put the coefficient matrix in <q>simplest</q> form, as in Example 12.1.3, or we may find that the situation of Example 12.1.1 evolves as part
of the process. In this latter case, we can terminate the process and state that the system has no solutions. The final matrix forms of Examples
12.1.1 and 12.1.3 are called echelon forms.



In practice, larger systems of linear equations are solved using computers. Generally, the Gauss-Jordan algorithm is the most useful; however, slight
variations of this algorithm are also used. The different approaches share many of the same advantages and disadvantages. The two major concerns
of all methods are:

<ol label=“1”>
<li><p>{ }minimizing inaccuracies due to rounding off errors, and

</p></li>
<li><p> { }minimizing computer time.



The accuracy of the Gauss-Jordan method can be improved by always choosing the element with the largest absolute value as the pivot element, as in
the following algorithm.

\pmb{ Algorithm 12.1.1.} Given a matrix equation \(A x = b\), where A is n $\times $ m, let <m>C</m> be the augmented matrix \([A | b]\). The
process of \pmb{ row-reducing to echelon form} involves performing the following algorithm where \(C_i = \text{the} i^{\text{th}} \text{row} \text{of}
C\):

\texttt{ i = 1\\
j = 1\\
}\texttt{ \pmb{ while}}\texttt{  (i $\leq $ n }\texttt{ \pmb{ and}}\texttt{  j $\leq $ m):\\
\hspace*{1.ex} $\#$ }\texttt{ \textit{ Find pivot in column j, starting in row i:}}\texttt{ \\
\hspace*{1.ex} maxi = i\\
 { }}\texttt{ \pmb{ for}}\texttt{  k = i+1 }\texttt{ \pmb{ to}}\texttt{  n:\\
 { } { }}\texttt{ \pmb{ if}}\texttt{  abs(C[k,j]) $>$ abs(C[maxi,j]) }\texttt{ \pmb{ then}}\texttt{ \\
\hspace*{3.ex} maxi := k\\
 { }}\texttt{ \pmb{ if}}\texttt{  C[maxi,j] $\neq $ 0 }\texttt{ \pmb{ then}}\texttt{ \\
\hspace*{2.ex} interchange rows i and maxi\\
\hspace*{2.ex} divide each entry in row i by C[i,j]\\
\hspace*{2.ex} $\#$ }\texttt{ \textit{ Now C[i,j] will have the value 1.}}\texttt{ \\
 { } { }}\texttt{ \pmb{ for}}\texttt{  u = i+1 }\texttt{ \pmb{ to}}\texttt{  n:\\
\hspace*{3.ex} subtract }\(C[u,j]*C_i\)\texttt{  { }from }\(C_u\)\texttt{ \\
\hspace*{3.ex} $\#$ }\texttt{ \textit{ Now C[u,j] will be 0}}\texttt{ \\
\hspace*{2.ex} i := i + 1\\
 { }}\texttt{ \pmb{ end if}}\texttt{ \\
\hspace*{1.ex} j = j + 1\\
}\texttt{ \pmb{ end while}}

At the end of this algorithm, with the final form of C you can revert back to the equation form of the system and a solution should be clear. { }In
general,\\
(a) If any row of C is all zeros, it can be ignored.\\
(b) { }If any row of C has all zero entries except for the entry in the \((m+1)^{\text{st}}\) position, the system has no solution. { } Otherwise,
if a column has no pivot, the variable corresponding to it is a \pmb{ free variable}. { }Variables corresponding to pivots are \pmb{ basic variables}
and can be expressed in terms of the free variables.



Example 12.1.4. If we apply Algorithm 12.1.1 to the system



 $\quad \quad $\(\begin{array}{l}
 5 x_1+x_2+2 x_3+x_4\text{  }=\text{  }2 \\
 3 x_1+x_2-2 x_3\text{             }=\text{   }5 \\
 \text{   }x_1+x_2+3 x_3\text{  }-x_{4 }=-1 \\
\end{array}\)



the augmented matrix



 { }$\quad \quad $\(C=\left(
\begin{array}{ccccc}
 5 &amp; 1 &amp; 2 &amp; 1 &amp; 2 \\
 3 &amp; 1 &amp; -2 &amp; 0 &amp; 5 \\
 1 &amp; 1 &amp; 3 &amp; -1 &amp; -1 \\
\end{array}
\right)\)



is reduced to a new value of \textit{ C:}



$\quad \quad $\(C=\left(
\begin{array}{ccccc}
 1 &amp; 0 &amp; 0 &amp; \frac{1}{2} &amp; \frac{1}{2} \\
 0 &amp; 1 &amp; 0 &amp; -\frac{3}{2} &amp; \frac{3}{2} \\
 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 \\
\end{array}
\right)\)



therefore \(x_4\) is a free variable in the solution and general solution of the system is



$\quad \quad $ { } { }\(x =\left(
\begin{array}{c}
 x_1 \\
 x_2 \\
 x_3 \\
 x_4 \\
\end{array}
\right)=\text{  }\left(
\begin{array}{c}
 \frac{1}{2}-\frac{1}{2}x_4 \\
 \frac{3}{2}+\frac{3}{2}x_4 \\
 -1 \\
 x_4 \\
\end{array}
\right)\)



This conclusion is easy to see if you revert back to the equations that the final value matrix <m>C</m> represents.



<subsubsection xml:id="sss-\(\) { "><title>\(\) { </title><index><main>\(\) { </main></index>\textit{ Mathematica} Note}



The \textit{ Mathematica} function \(RowReduce\) does the same reduction as described in Algorithm 12.1.1. { }For example, here is the result for
the system in Example 12.1.4. 

\begin{doublespace}
\noindent\(\pmb{\text{RowReduce}\left[\right]}\)
\end{doublespace}

\begin{doublespace}
\noindent\(\left(
\begin{array}{ccccc}
 1 &amp; 0 &amp; 0 &amp; \frac{1}{2} &amp; \frac{1}{2} \\
 0 &amp; 1 &amp; 0 &amp; -\frac{3}{2} &amp; \frac{3}{2} \\
 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 \\
\end{array}
\right)\)
\end{doublespace}

\begin{doublespace}
\noindent\(\pmb{\text{Options}[\text{RowReduce}]}\)
\end{doublespace}

\begin{doublespace}
\noindent\(\{\text{Method}\to \text{Automatic},\text{Modulus}\to 0,\text{Tolerance}\to \text{Automatic},\text{ZeroTest}\to \text{Automatic}\}\)
\end{doublespace}



Only one caution: { }One needs to be aware that if the pivoting process continues into the last column, which \textit{ Mathematica} will do, there
will not be a solution to the system. { }For example the system 



$\quad \quad $\(\begin{array}{l}
 2 x_1\text{  }-x_2=1 \\
 3 x_2\text{  }-x_1=5 \\
 x_1\text{  }+5 x_2=7 \\
\end{array}\)



has augmented matrix



 $\quad \quad $\(C=\left(
\begin{array}{ccc}
 2 &amp; -1 &amp; 1 \\
 -1 &amp; 3 &amp; 5 \\
 1 &amp; 5 &amp; 7 \\
\end{array}
\right)\).



Here is the computation to row-reduce:

\begin{doublespace}
\noindent\(\pmb{\text{RowReduce}\left[\right]}\)
\end{doublespace}

\begin{doublespace}
\noindent\(\left(
\begin{array}{ccc}
 1 &amp; 0 &amp; 0 \\
 0 &amp; 1 &amp; 0 \\
 0 &amp; 0 &amp; 1 \\
\end{array}
\right)\)
\end{doublespace}



The last row of the final form of <m>C</m> is { }\(0=1\) and so there is no solution to the original system.



<subsubsection xml:id="sss-\(\) { "><title>\(\) { </title><index><main>\(\) { </main></index>Sage Note}



Given an augmented matrix, <m>C</m>, there is a matrix method called \(eschewing$\_$form\) that can be used to row reduce <m>C</m>. { } Here
is the result for the system in Example 12.1.4. { } In the assignment of a matrix value to \(C\), notice that the first argument is QQ, which indicates
that the entries should be rational numbers. { } As long as all the entries are rational, which is the case here since integers are rational, the
row-reduced matrix will be all rational. 

C = Matrix(QQ,[[5,1,2,1,2],[3,1,-2,0,5],[1,1,3,-1,-1]])\\
C.echelon$\_$form()\\
\texttt{ $\quad $[ { } 1 { } { }0 { } { }0 { }1/2 { }1/2]\\
$\quad $[ { } 0 { } { }1 { } { }0 -3/2 { }3/2]\\
$\quad $[ { } 0 { } { }0 { } { }1 { } { }0 { } -1]}



If we didn't specify the set from which entries are taken, it would assumed to be the integers and we would not get a fully row-reduced matrix. {
} The next step would involve multiplying row 3 by \(\frac{1}{9}\), which isn't an integer.

C2 = Matrix([[5,1,2,1,2],[3,1,-2,0,5],[1,1,3,-1,-1]])\\
C2.echelon$\_$form() { } { } { }$\quad $\texttt{ \\
$\quad $[ 1 { }1 { }3 -1 -1]\\
$\quad $[ 0 { }2 { }2 -3 { }1]\\
$\quad $[ 0 { }0 { }9 { }0 -9]}



This is why we would avoid specifying real entries:

C3 = Matrix(RR,[[5,1,2,1,2],[3,1,-2,0,5],[1,1,3,-1,-1]])\\
C3.echelon$\_$form() { } { } { }$\quad $ { } { } { } $\quad $\texttt{ \\
}\texttt{ [ { } { }1.00000000000000 { } { }0.000000000000000 { } { }0.000000000000000 { } { }0.500000000000000 { } { }0.500000000000000]\\
[ { } 0.000000000000000 { } { } 1.00000000000000 { } { }0.000000000000000 { } { }-1.50000000000000 { } { } 1.50000000000000]\\
[ { } 0.000000000000000 { } { }0.000000000000000 { } { } 1.00000000000000 4.93432455388958e-17 { } { }-1.00000000000000]}



This is the default number of decimal places, which could be controlled and the single small number in row three column four isn't exactly zero because
of round-off and we could just set it to zero. { }However, the result isn't as nice and clean as the rational output in this case.


<exercises xml:id="exercises-12-1">
<title>Exercises for Section 12.1</title>



<exercisegroup>
<introduction><p>A Exercises</p></introduction>

<exercise number="1"><statement> Solve the following systems by describing the solution sets completely:

<ol label=“a”>
<li><p> { } \(\begin{array}{l}
 2 x_1+x_2=3 \\
 x_1-x_2=1 \\
\end{array}\)

</p></li>
<li><p> { }\(\begin{array}{l}
 2 x_1+x_2+3 x_3=5 \\
 4 x_1+x_2+2 x_3=-1 \\
 8 x_1+2 x_2+4 x_3=-2 \\
\end{array}\)

</p></li>
<li><p> { }\(\begin{array}{l}
 x_1+x_2+2 x_3=1 \\
 x_1+2 x_2-x_3=-1 \\
 x_1+3 x_2+x_3=5 \\
\end{array}\)

</p></li>
<li><p> { }\(\begin{array}{l}
 x_1-x_2+3 x_3=7 \\
 x_1+3 x_2+x_3=4 \\
\end{array}\)
</statement></exercise>
<exercise number="2"><statement>Solve the following systems by describing the solution sets completely:

<ol label=“a”>
<li><p> { } \(\begin{array}{l}
 2 x_1+2 x_2+4 x_3=2 \\
 2 x_1+x_2+4 x_3=0 \\
 3 x_1+5 x_2+x_3=0 \\
\end{array}\)

</p></li>
<li><p> { }\(\begin{array}{l}
 2 x_1+x_2+3 x_3=2 \\
 4 x_1+x_2+2 x_3=-1 \\
 8 x_1+2 x_2+4 x_3=4 \\
\end{array}\)

</p></li>
<li><p> { }\(\begin{array}{l}
 x_1+x_2+2 x_3+x_4=3 \\
 x_1-x_2+3 x_3-x_4=-2 \\
 3 x_1+3 x_2+6 x_3+3 x_4=9 \\
\end{array}\)

</p></li>
<li><p> { }\(\begin{array}{l}
 6 x_1+7 x_2+2 x_3=3 \\
 4 x_1+2 x_2+x_3=-2 \\
 6 x_1+x_2+x_3=1 \\
\end{array}\)

</p></li>
<li><p> { }\(\begin{array}{l}
 x_1+x_2-x_3+2 x_4=1 \\
 x_1+2 x_2+3 x_3+x_4=5 \\
 x_1+3 x_2+2 x_3-x_4=-1 \\
\end{array}\)
</statement></exercise>
<exercise number="3"><statement>Given that the final augmented matrices below obtained from Algorithm 12.1.1, identify the solutions sets. Identify the basic and free variables,
and describe the solution set of the original system. 

<ol label=“a”>
<li><p> { } \(\left(
\begin{array}{ccccc}
 1 &amp; 0 &amp; -5 &amp; 0 &amp; 1.2 \\
 0 &amp; 1 &amp; 4 &amp; 0 &amp; 2.6 \\
 0 &amp; 0 &amp; 0 &amp; 1 &amp; 4.5 \\
\end{array}
\right)\)$\quad \quad \quad $(c) { } \(\left(
\begin{array}{cccc}
 1 &amp; 0 &amp; 9 &amp; 3 \\
 0 &amp; 1 &amp; 0 &amp; 4 \\
 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{array}
\right)\)





</p></li>
<li><p> { } { }\(\left(
\begin{array}{cccc}
 1 &amp; 0 &amp; 6 &amp; 5 \\
 0 &amp; 1 &amp; -2 &amp; 1 \\
 0 &amp; 0 &amp; 0 &amp; 0 \\
\end{array}
\right)\)$\quad \quad \quad $(d) { }\(\left(
\begin{array}{ccccc}
 1 &amp; 0 &amp; 0 &amp; -3 &amp; 1 \\
 0 &amp; 1 &amp; 0 &amp; 2 &amp; 2 \\
 0 &amp; 0 &amp; 1 &amp; -1 &amp; 1 \\
\end{array}
\right)\)
</statement></exercise>
<exercise number="4"><statement>(a) Write out the details of Example 12.1.2.

</p></li>
<li><p>Write out the details of Example 12.1.3.

</p></li>
<li><p>Write out the details of Example 12.1.4.
</statement></exercise>
<exercise number="5"><statement>Solve the following systems using only mod 5 arithmetic. Your solutions should be \(n-\text{tuples}\) from \(\mathbb{Z}_5\).

<ol label=“a”>
<li><p> { }\(\begin{array}{l}
 2 x_1+ x_2=3 \\
  x_1+4 x_2=1 \\
\end{array}\) { } { }(compare your solution to the system in 5(a))

</p></li>
<li><p> { } \(\begin{array}{l}
 x_1+x_2+2 x_3=1 \\
 x_1+2 x_2+4 x_3=4 \\
 x_1+3 x_2+3 x_3=0 \\
\end{array}\)
</statement></exercise>
<exercise number="6"><statement>(a) Use the solution set <m>S</m> of Example 12.1.3 to list three different solutions to the given system. Then show that each of these solutions
can be described by the set A of Example 12.1.3.



 { } { }(b)Prove that S = A.


</exercisegroup>
<exercisegroup>
<introduction><p>B Exercises</p></introduction>
</statement></exercise>
<exercise number="7"><statement>Given a system of <m>n</m> linear equations in <m>n</m> unknowns in matrix form \(A x = b\), prove that if <m>b</m> is a matrix of all
zeros, then the solution set of \(A x = b\) is a subgroup of \(\mathbb{R}^n\).